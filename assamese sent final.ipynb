{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa13385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c21c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8263cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,classification_report\n",
    "from scikitplot.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fded4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Documents\\\\Assamese_Sentiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21741638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assamese Text</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>কিছুমান ইস্ৰায়েলে কেনে ধৰণৰ অন্যায়পূৰ্ণ কাৰ্য্...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>বৰ্তমান পশ্চিম বংগৰ বিজেপিৰ মহাসচিব হিচাপে কাৰ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>নতুন ফোল্ডাৰ `%s' নিৰ্মাণ কৰা সম্ভব নহয়</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>তাৰবাবে আমাৰ দেশৰ যুবশক্তিক আমি চাকৰি প্ৰত্যাশ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>মই ইয়াত আছো!</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Assamese Text Sentiments\n",
       "0  কিছুমান ইস্ৰায়েলে কেনে ধৰণৰ অন্যায়পূৰ্ণ কাৰ্য্...   Negative\n",
       "1  বৰ্তমান পশ্চিম বংগৰ বিজেপিৰ মহাসচিব হিচাপে কাৰ...    Neutral\n",
       "2            নতুন ফোল্ডাৰ `%s' নিৰ্মাণ কৰা সম্ভব নহয়    Neutral\n",
       "3  তাৰবাবে আমাৰ দেশৰ যুবশক্তিক আমি চাকৰি প্ৰত্যাশ...    Neutral\n",
       "4                                       মই ইয়াত আছো!    Neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97bb2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_24 = df.iloc[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a90095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df.Sentiments=le.fit_transform(df.Sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05709ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assamese Text</th>\n",
       "      <th>Sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>কিছুমান ইস্ৰায়েলে কেনে ধৰণৰ অন্যায়পূৰ্ণ কাৰ্য্...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>বৰ্তমান পশ্চিম বংগৰ বিজেপিৰ মহাসচিব হিচাপে কাৰ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>নতুন ফোল্ডাৰ `%s' নিৰ্মাণ কৰা সম্ভব নহয়</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>তাৰবাবে আমাৰ দেশৰ যুবশক্তিক আমি চাকৰি প্ৰত্যাশ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>মই ইয়াত আছো!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Assamese Text  Sentiments\n",
       "0  কিছুমান ইস্ৰায়েলে কেনে ধৰণৰ অন্যায়পূৰ্ণ কাৰ্য্...           0\n",
       "1  বৰ্তমান পশ্চিম বংগৰ বিজেপিৰ মহাসচিব হিচাপে কাৰ...           1\n",
       "2            নতুন ফোল্ডাৰ `%s' নিৰ্মাণ কৰা সম্ভব নহয়           1\n",
       "3  তাৰবাবে আমাৰ দেশৰ যুবশক্তিক আমি চাকৰি প্ৰত্যাশ...           1\n",
       "4                                       মই ইয়াত আছো!           1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc0369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['Assamese Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee25b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a05a714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "from indicnlp.morph import unsupervised_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "223adc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "   assamese_stopwords = [ 'অতএব', 'অথচ', 'অথবা', 'অধঃ', 'অন্ততঃ', 'অর্থাৎ', 'অর্থে', 'আও', 'আঃ', 'আচ্ছা', \n",
    "    'আপাততঃ', 'আয়ৈ', 'আৰু', 'আস্', 'আহা', 'আহাহা', 'ইতস্ততঃ', 'ইতি', 'ইত্যাদি', \n",
    "    'ইস্', 'ইহ', 'উঃ', 'উৱা', 'উস্', 'এতেকে', 'এথোন', 'ঐ', 'ওঁ', 'ওৰফে', 'ঔচ্', \n",
    "    'কি', 'কিম্বা', 'কিন্তু', 'কিয়নো', 'কেলেই', 'কাচিত্', 'চোন', 'ছাৰি', 'ছিকৌ', 'ছেই', \n",
    "    'ঠাহ্', 'ঢুত্', 'ঢেঁট্', 'তত', 'ততক', 'ততেক', 'তেতেক', 'ততেক', 'তত্ৰাচ', \n",
    "    'তথা', 'তথৈবচ', 'তাতে', 'তো', 'তৌৱা', 'দেই', 'দেহি', 'দ্বাৰা', 'ধৰি', 'ধিক্', 'নচেত্', \n",
    "    'নতুবা', 'নি', 'নো', 'নৌ', 'পৰা', 'পৰ্যন্ত', 'পশ্চাত্', 'বৰঞ্চ', 'বহিঃ', 'বাবে', \n",
    "    'বাৰু', 'বাহ্', 'বাহিৰে', 'বিনে', 'বে', 'মতে', 'যথা', 'যদি', 'যদ্যপি', 'যে', 'যেনিবা', \n",
    "    'যেনে', 'যোগে', 'লৈ', 'সত্ত্বে', 'সমন্ধি', 'সম্প্ৰতি', 'সহ', 'সু', 'সেইদেখি', 'সৈতে', \n",
    "    'স্বতঃ', 'হঞে', 'হতুৱা', 'হন্তে', 'হবলা', 'হয়', 'হা', 'হুঁ', 'হুই', 'হে', 'হেই', 'হেঃ', \n",
    "    'হেতুকে', 'হেনে', 'হেনো', 'হেৰ', 'হেৰি', 'হৈ', 'হোঁ', 'ইঃ', 'ইচ্', 'চুহ্', 'চুঃ', \n",
    "    'আঁ'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8c0fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transformation_indic(df_col):\n",
    "    corpus = []\n",
    "    # Initialize the IndicNormalizerFactory\n",
    "    factory = IndicNormalizerFactory()\n",
    "    normalizer = factory.get_normalizer(\"as\")\n",
    "\n",
    "    for item in df_col:\n",
    "        # Normalizing text\n",
    "        new_item = normalizer.normalize(item)\n",
    "        # Tokenizing and removing stopwords\n",
    "        tokens = indic_tokenize.trivial_tokenize(new_item)\n",
    "        filtered_tokens = [token for token in tokens if token not in assamese_stopwords]\n",
    "        # Join the filtered tokens\n",
    "        filtered_text = ' '.join(filtered_tokens)\n",
    "        # Append the filtered text to the corpus\n",
    "        corpus.append(filtered_text)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5412e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preprocessed = text_transformation_indic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e49871b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['কিছুমান ইস্ৰায়েলে কেনে ধৰণৰ অন্যায়পূৰ্ণ কাৰ্য্যত লিপ্ত আছিল ?',\n",
       " 'বৰ্তমান পশ্চিম বংগৰ বিজেপিৰ মহাসচিব হিচাপে কাৰ্যনিৰ্বাহ ।',\n",
       " \"নতুন ফোল্ডাৰ ` % s ' নিৰ্মাণ কৰা সম্ভব নহয়\",\n",
       " 'তাৰবাবে আমাৰ দেশৰ যুবশক্তিক আমি চাকৰি প্ৰত্যাশীৰ বিপৰীতে চাকৰি সৃষ্টিকাৰী হিচাপে গঢ়ি তুলিব বিচাৰো ।',\n",
       " 'মই ইয়াত আছো !']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_preprocessed[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46ab73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df = df.dropna()\n",
    "vectorizer = TfidfVectorizer(max_features=4000)  \n",
    "X_vectorized = vectorizer.fit_transform(X_preprocessed)\n",
    "X_vectorized = X_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc70dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectorized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e4ce864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf1c50dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd40431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d8b538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3023/3023 [==============================] - 57s 18ms/step - loss: 0.9016 - accuracy: 0.6173 - val_loss: 0.8948 - val_accuracy: 0.6199\n",
      "Epoch 2/5\n",
      "3023/3023 [==============================] - 33s 11ms/step - loss: 0.8894 - accuracy: 0.6175 - val_loss: 0.9012 - val_accuracy: 0.6199\n",
      "Epoch 3/5\n",
      "3023/3023 [==============================] - 36s 12ms/step - loss: 0.8791 - accuracy: 0.6186 - val_loss: 0.9050 - val_accuracy: 0.6186\n",
      "Epoch 4/5\n",
      "3023/3023 [==============================] - 34s 11ms/step - loss: 0.8635 - accuracy: 0.6222 - val_loss: 0.9148 - val_accuracy: 0.6133\n",
      "Epoch 5/5\n",
      "3023/3023 [==============================] - 36s 12ms/step - loss: 0.8415 - accuracy: 0.6302 - val_loss: 0.9310 - val_accuracy: 0.6028\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, input_shape=(4000,), activation='relu'),    \n",
    "    layers.Dense(3, activation='softmax')  \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',  \n",
    "    loss='sparse_categorical_crossentropy',  \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test, y_test), \n",
    "    batch_size=32  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d5f9586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir una lista de nombres de modelos y sus correspondientes instancias\n",
    "models = [\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('CatBoostClassifier', CatBoostClassifier(verbose=0)),\n",
    "    ('LGBMClassifier', LGBMClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('SVC', SVC(probability=True))\n",
    "    # Agrega otros clasificadores si deseas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a8767b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Definir una lista de nombres de modelos y sus correspondientes instancias\n",
    "models = [\n",
    "    ('XGBClassifier', XGBClassifier()),\n",
    "    ('CatBoostClassifier', CatBoostClassifier(verbose=0)),\n",
    "    ('LGBMClassifier', LGBMClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('SVC', SVC(probability=True))\n",
    "    # Agrega otros clasificadores si deseas\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f7972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBClassifier...\n",
      "XGBClassifier Accuracy Score: 0.62\n",
      "--------------------------------------\n",
      "Training CatBoostClassifier...\n",
      "CatBoostClassifier Accuracy Score: 0.62\n",
      "--------------------------------------\n",
      "Training LGBMClassifier...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.335545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 97541\n",
      "[LightGBM] [Info] Number of data points in the train set: 96736, number of used features: 1488\n",
      "[LightGBM] [Info] Start training from score -2.201929\n",
      "[LightGBM] [Info] Start training from score -0.482017\n",
      "[LightGBM] [Info] Start training from score -1.302417\n",
      "LGBMClassifier Accuracy Score: 0.62\n",
      "--------------------------------------\n",
      "Training RandomForestClassifier...\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models:\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_pred, y_test)\n",
    "    print(f\"{model_name} Accuracy Score: {score:.2f}\")\n",
    "    print(f\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fec555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
